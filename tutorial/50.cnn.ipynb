{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "(c) Deniz Yuret, 2019\n",
    "* Objectives: See the effect of sparse and shared weights implemented by convolutional networks.\n",
    "* Prerequisites: [MLP models](40.mlp.ipynb), [MNIST](20.mnist.ipynb)\n",
    "* New functions:\n",
    "[conv4](http://denizyuret.github.io/Knet.jl/latest/reference/#Knet.conv4),\n",
    "[pool](http://denizyuret.github.io/Knet.jl/latest/reference/#Knet.pool),\n",
    "[mat](http://denizyuret.github.io/Knet.jl/latest/reference/#Knet.mat)\n",
    "\n",
    "![image](https://github.com/denizyuret/Knet.jl/blob/master/docs/src/images/le_net.png?raw=true)\n",
    "([image source](http://www.dataiku.com/blog/2015/08/18/Deep_Learning.html))\n",
    "\n",
    "To improve the performance further, we can use a convolutional neural networks (CNN). See the [course notes](http://cs231n.github.io/convolutional-networks/) by Andrej Karpathy for a good introduction to CNNs. We will implement the [LeNet](http://yann.lecun.com/exdb/lenet) model which consists of two convolutional layers followed by two fully connected layers. We will describe and use the [conv4](http://denizyuret.github.io/Knet.jl/latest/reference/#Knet.conv4) and [pool](http://denizyuret.github.io/Knet.jl/latest/reference/#Knet.pool) functions provided by Knet for the implementation of convolutional nets.\n",
    "\n",
    "Even though MLPs and CNNs are both universal function approximators and both achieve 0 error on the training set, we will see that a CNN converges a lot faster and generalizes a lot better with less overfitting achieving a 99.5% test accuracy on MNIST. The sparse connectivity and shared weights of a CNN give it an inductive bias appropriate for image features allowing it to learn better with less data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Setup display width, load packages, import symbols\n",
    "ENV[\"COLUMNS\"]=72\n",
    "using Base.Iterators: flatten\n",
    "using IterTools: ncycle, takenth\n",
    "using Statistics: mean\n",
    "using MLDatasets: MNIST\n",
    "import CUDA # functional\n",
    "using Knet: Knet, conv4, pool, mat, KnetArray, nll, zeroone, progress, sgd, param, param0, dropout, relu, minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution operator in Knet\n",
    "@doc conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution in 1-D\n",
    "w = reshape([1.0,2.0,3.0], (3,1,1,1)); @show w\n",
    "x = reshape([1.0:7.0...], (7,1,1,1)); @show x\n",
    "@show y = conv4(w, x);  # size Y = X - W + 1 = 5 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Padding\n",
    "w = reshape([1.0,2.0,3.0], (3,1,1,1)); @show w\n",
    "x = reshape([1.0:7.0...], (7,1,1,1)); @show x\n",
    "@show y2 = conv4(w, x, padding=(1,0));  # size Y = X + 2P - W + 1 = 7 with padding=1\n",
    "# To preserve input size (Y=X) for a given W, what padding P should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Stride\n",
    "w = reshape([1.0,2.0,3.0], (3,1,1,1)); @show w\n",
    "x = reshape([1.0:7.0...], (7,1,1,1)); @show x\n",
    "@show y3 = conv4(w, x; padding=(1,0), stride=3);  # size Y = 1 + floor((X+2P-W)/S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mode\n",
    "w = reshape([1.0,2.0,3.0], (3,1,1,1)); @show w\n",
    "x = reshape([1.0:7.0...], (7,1,1,1)); @show x\n",
    "@show y4 = conv4(w, x, mode=0);  # Default mode (convolution) inverts w\n",
    "@show y5 = conv4(w, x, mode=1);  # mode=1 (cross-correlation) does not invert w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution in more dimensions\n",
    "x = reshape([1.0:9.0...], (3,3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "w = reshape([1.0:4.0...], (2,2,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = conv4(w, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution with multiple channels, filters, and instances\n",
    "# size X = [X1,X2,...,Xd,Cx,N] where d is the number of dimensions, Cx is channels, N is instances\n",
    "x = reshape([1.0:18.0...], (3,3,2,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# size W = [W1,W2,...,Wd,Cx,Cy] where d is the number of dimensions, Cx is input channels, Cy is output channels\n",
    "w = reshape([1.0:24.0...], (2,2,2,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# size Y = [Y1,Y2,...,Yd,Cy,N]  where Yi = 1 + floor((Xi+2Pi-Wi)/Si), Cy is channels, N is instances\n",
    "y = conv4(w,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "See http://cs231n.github.io/assets/conv-demo/index.html for an animated example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Pooling operator in Knet\n",
    "@doc pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 1-D pooling example\n",
    "x = reshape([1.0:6.0...], (6,1,1,1)); @show x\n",
    "@show pool(x; window=(2,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Window size\n",
    "x = reshape([1.0:6.0...], (6,1,1,1)); @show x\n",
    "@show pool(x; window=(3,1));  # size Y = floor(X/W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Padding\n",
    "x = reshape([1.0:6.0...], (6,1,1,1)); @show x\n",
    "@show pool(x; window=(2,1), padding=(1,0));  # size Y = floor((X+2P)/W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Stride\n",
    "x = reshape([1.0:10.0...], (10,1,1,1)); @show x\n",
    "@show pool(x; window=(2,1), stride=4);  # size Y = 1 + floor((X+2P-W)/S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mode (using KnetArray here; not all modes are implemented on the CPU)\n",
    "if CUDA.functional()\n",
    "    x = KnetArray(reshape([1.0:6.0...], (6,1,1,1))); @show x\n",
    "    @show pool(x; padding=(1,0), mode=0)  # max pooling\n",
    "    @show pool(x; padding=(1,0), mode=1)  # avg pooling\n",
    "    @show pool(x; padding=(1,0), mode=2); # avg pooling excluding padded values (is not implemented on CPU)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# More dimensions\n",
    "x = reshape([1.0:16.0...], (4,4,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Multiple channels and instances\n",
    "x = reshape([1.0:32.0...], (4,4,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# each channel and each instance is pooled separately\n",
    "pool(x)  # size Y = (Y1,...,Yd,Cx,N) where Yi are spatial dims, Cx and N are identical to input X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "xtrn,ytrn = MNIST.traindata(Float32); ytrn[ytrn.==0] .= 10\n",
    "xtst,ytst = MNIST.testdata(Float32);  ytst[ytst.==0] .= 10\n",
    "dtrn = minibatch(xtrn, ytrn, 100; xsize = (28,28,1,:), xtype = Knet.array_type[])\n",
    "dtst = minibatch(xtst, ytst, 100; xsize = (28,28,1,:), xtype = Knet.array_type[]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(x,y) = first(dtst)\n",
    "println.(summary.((x,y)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# For running experiments\n",
    "function trainresults(file,model; o...)\n",
    "    if (print(\"Train from scratch? \"); readline()[1]=='y')\n",
    "        r = ((model(dtrn), model(dtst), zeroone(model,dtrn), zeroone(model,dtst))\n",
    "             for x in takenth(progress(sgd(model,ncycle(dtrn,100))),length(dtrn)))\n",
    "        r = reshape(collect(Float32,flatten(r)),(4,:))\n",
    "        Knet.save(file,\"results\",r)\n",
    "        GC.gc(true) # To save gpu memory\n",
    "    else\n",
    "        isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "        r = Knet.load(file,\"results\")\n",
    "    end\n",
    "    println(minimum(r,dims=2))\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A convolutional neural network model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a convolutional layer:\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Redefine dense layer (See mlp.ipynb):\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's define a chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = nll(c(x),y)\n",
    "(c::Chain)(d::Data) = mean(c(x,y) for (x,y) in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lenet =   Chain(Conv(5,5,1,20), \n",
    "                Conv(5,5,20,50), \n",
    "                Dense(800,500,pdrop=0.3), \n",
    "                Dense(500,10,identity,pdrop=0.3))\n",
    "summary.(l.w for l in lenet.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lenet(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNN vs MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 1.08e-02  100.00%┣████████████████▉┫ 60000/60000 [03:50/03:50, 260.67i/s]\n",
    "# [0.000135032; 0.0196918; 0.0; 0.0053]\n",
    "cnn = trainresults(\"cnn113.jld2\", lenet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlp = Knet.load(\"mlp113f.jld2\",\"results\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "using Plots; default(fmt=:png,ls=:auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison to MLP shows faster convergence, better generalization\n",
    "plot([mlp[1,:], mlp[2,:], cnn[1,:], cnn[2,:]],ylim=(0.0,0.1),\n",
    "     labels=[\"trnMLP\" \"tstMLP\" \"trnCNN\" \"tstCNN\"],xlabel=\"Epochs\",ylabel=\"Loss\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot([mlp[3,:], mlp[4,:], cnn[3,:], cnn[4,:]],ylim=(0.0,0.03),\n",
    "    labels=[\"trnMLP\" \"tstMLP\" \"trnCNN\" \"tstCNN\"],xlabel=\"Epochs\",ylabel=\"Error\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolution vs Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution and matrix multiplication can be implemented in terms of each other.\n",
    "# Convolutional networks have no additional representational power, only statistical efficiency.\n",
    "# Our original 1-D example\n",
    "@show w = reshape([1.0,2.0,3.0], (3,1,1,1))\n",
    "@show x = reshape([1.0:7.0...], (7,1,1,1))\n",
    "@show y = conv4(w, x);  # size Y = X - W + 1 = 5 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution as matrix multiplication (1)\n",
    "# Turn w into a (Y,X) sparse matrix\n",
    "w2 = Float64[3 2 1 0 0 0 0; 0 3 2 1 0 0 0; 0 0 3 2 1 0 0; 0 0 0 3 2 1 0; 0 0 0 0 3 2 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@show y2 = w2 * mat(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution as matrix multiplication (2)\n",
    "# Turn x into a (W,Y) dense matrix (aka the im2col operation)\n",
    "# This is used to speed up convolution with known efficient matmul algorithms\n",
    "x3 = Float64[1 2 3 4 5; 2 3 4 5 6; 3 4 5 6 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@show w3 = [3.0 2.0 1.0]\n",
    "@show y3 = w3 * x3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Matrix multiplication as convolution\n",
    "# This could be used to make a fully connected network accept variable sized inputs.\n",
    "w = reshape([1.0:6.0...], (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = reshape([1.0:3.0...], (3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Consider w with size (Y,X)\n",
    "# Treat each of the Y rows of w as a convolution filter\n",
    "w2 = copy(reshape(Array(w)', (3,1,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape x for convolution\n",
    "x2 = reshape(x, (3,1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Use conv4 for matrix multiplication\n",
    "y2 = conv4(w2, x2; mode=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* So there is no difference between the class of functions representable with an MLP vs CNN.\n",
    "* Sparse connections and weight sharing give CNNs more generalization power with images.\n",
    "* Number of parameters in MLP256: (256x784)+256+(10x256)+10 = 203530\n",
    "* Number of parameters in LeNet: (5*5*1*20)+20+(5*5*20*50)+50+(500*800)+500+(10*500)+10 = 431080"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "julia.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
